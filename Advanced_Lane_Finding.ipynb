{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "***\n",
    "## Project 2: **Advanced Lane Finding** \n",
    "\n",
    "#### **Written by: Philip Renn**\n",
    "\n",
    "[image]: ./output_images/writeup_images/result.png\n",
    "---\n",
    "\n",
    "![alt text][image]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Goal\n",
    "    Calibrate a 2D camera using chessboard calibration images to a aquire a conversion matrix and distortion coefficients.   \n",
    "\n",
    "## Primary Goal\n",
    "    Write a sofetware pipeline to identiify the lane boundaries from raw images from a video.\n",
    "\n",
    "### Steps:\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Import packages to edit/save/watch video clips\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Initialize Variables\n",
    "These variables are used in pipeline functions which are called for each raw image in the video. By initializing these variables outside of the functions, processing time is reduced without affecting the result as their values are not modified by the funtions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "###################### INITIALIZE VARIABLES ######################\n",
    "# Load camera calibration file and extract cals \n",
    "pickle_dict = pickle.load(open(\"calibration_data.p\", \"rb\"))\n",
    "mtx = pickle_dict[\"mtx\"]\n",
    "dist = pickle_dict[\"dist\"]\n",
    "\n",
    "#### Perspective Transform Variables ####\n",
    "# Set offset for destination points\n",
    "offsetx = 400\n",
    "# Defining trapezoid points for src image \n",
    "imshape = (720, 1280)\n",
    "left_bottom_p = [217, 705]\n",
    "left_top_p = [588, 453]\n",
    "right_top_p = [694, 453]\n",
    "right_bottom_p = [1100, 705]\n",
    "# Set src and dest points and get matrix (and inverse) to warp perspective\n",
    "# Define 4 source points src = np.float32([[,],[,],[,],[,]])\n",
    "src = np.float32([[left_bottom_p, left_top_p, right_top_p, right_bottom_p]], dtype=np.int32)\n",
    "# Define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "dst = np.float32([[offsetx, imshape[0]],[offsetx, 0],[imshape[1]-offsetx, 0],[imshape[1]-offsetx, imshape[0]]])\n",
    "# Use cv2.getPerspectiveTransform() to get M, the transform matrix, and its inverse, Minv\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "#### Region of Interest Variables ####\n",
    "# Set 'verticies' for ROI mask\n",
    "left_bottom = [300, imshape[0]]\n",
    "left_top = [0,0]\n",
    "right_top = [int(imshape[1]), 0]\n",
    "right_bottom = [int(imshape[1] - 300), int(imshape[0])]\n",
    "vertices = np.array([[left_bottom, left_top, right_top, right_bottom]], dtype=np.int32)\n",
    "\n",
    "#### Thesholds for Color Layers ####\n",
    "# Defining color space thresholds for R, H, L, S layers\n",
    "R_thresh = (220,255)  # Red:        {0-255}\n",
    "H_thresh = (25,100)   # Hue:        {0-180}\n",
    "L_thresh = (0,190)    # Lightness:  {0-255}\n",
    "S_thresh = (100,255)  # Saturation: {0-255}\n",
    "############################## (END) #############################\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Image Processing Functions\n",
    "The following funtions are called to filter the lane line pixels which will be used to determine the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "################## IMAGE PROCESING FUNCTIONS #####################\n",
    "def undistort(img):\n",
    "    ''' Corrects for distortion caused by camera lenses '''\n",
    "    return cv2.undistort(img,mtx,dist,None,mtx)\n",
    "\n",
    "def elevate_perspective(img):\n",
    "    ''' Warps image to achieve a top-down view of road '''\n",
    "    # Use cv2.warpPerspective() to warp input image to a top-down view\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # Use 'M' imported from 'calibration_data.p' file\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def sobel(img):\n",
    "    '''\n",
    "    Performs sobel operation to get the gradient in x & y direction.\n",
    "    Thresholds the magnitude direction which is achieved using x & y gradients\n",
    "    Returns images for x-direction gradient and the thresholded magnitude direction. \n",
    "    '''\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Take the derivative in x & y\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)    \n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobelx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Create a mask of 1's where the scaled gradient magnitude is within threshold\n",
    "    sobel_thresh = (30,255)\n",
    "    gradx = np.zeros_like(scaled_sobelx)\n",
    "    gradx[(scaled_sobelx >= sobel_thresh[0]) & (scaled_sobelx <= sobel_thresh[1])] = 1\n",
    "    # Get the binary image of the thresholded magnitude direction\n",
    "    dir_binary = sobel_mag_dir(abs_sobelx, abs_sobely)\n",
    "    return gradx, dir_binary\n",
    "\n",
    "def sobel_magnitude(gray, mag_thresh=(50,255)):\n",
    "    ''' Retuns a binary thesholded image of gradient magnitude. '''\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=9)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=9)\n",
    "    gradmag = np.hypot(sobelx, sobely)\n",
    "    # Scale magnitude from 0-255\n",
    "    gradmag = (gradmag / (np.max(gradmag)/255)).astype(np.uint8)\n",
    "    # Create binary image of thresholded magnitude\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def sobel_mag_dir(abs_sobelx, abs_sobely, dir_thresh=(0.0, 0.3)):\n",
    "    ''' Returns thesholded binary image of magitude direction from sobel gradients '''\n",
    "    # Calculate absolute direction of gradient\n",
    "    absgraddir = np.arctan2(abs_sobelx, abs_sobely)\n",
    "    # Create binary image of thresholded gradient direction\n",
    "    binary_output = np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= dir_thresh[0]) & (absgraddir <= dir_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def bgr2hls(img):\n",
    "    ''' Converts BGR image to HLS color space '''\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HLS) \n",
    "\n",
    "def color_mask(img, img_hls):\n",
    "    \"\"\"\n",
    "    Applies a color selection mask to find yellow & white lane line pixel values.\n",
    "    Converts input image to HLS color space and thresholds each layer and performs\n",
    "    bitwise operations with the Red layer from BGR image.\n",
    "    \n",
    "    Returns a color-masked binary image.\n",
    "    \"\"\"\n",
    "    # Grab R layer of BGR image and H,L,S layers from HLS image\n",
    "    R = img[:,:,2]\n",
    "    H = img_hls[:,:,0]\n",
    "    L = img_hls[:,:,1]\n",
    "    S = img_hls[:,:,2]\n",
    "    \n",
    "    # Applying color thresholds using color space thresholds for R, H, L, S layers\n",
    "    R_binary = np.zeros_like(R)\n",
    "    R_binary[(R >= R_thresh[0]) & (L >= 150)] = 1\n",
    "    H_binary = np.zeros_like(H)\n",
    "    H_binary[(H >= H_thresh[0]) & (H <= H_thresh[1])] = 1\n",
    "    L_binary = np.zeros_like(L)\n",
    "    L_binary[(L >= L_thresh[0]) & (L <= L_thresh[1])] = 1\n",
    "    S_binary = np.zeros_like(S)\n",
    "    S_binary[(S >= S_thresh[0]) & (S <= S_thresh[1])] = 1\n",
    "    \n",
    "    # Combine hue and Lightness layers to detect lane lines in darker areas (e.g. shadows)\n",
    "    HL_binary = cv2.bitwise_and(H_binary, L_binary)\n",
    "\n",
    "    # Combine all thresholded layers\n",
    "    mask_binary = np.zeros_like(R)\n",
    "    mask_binary = cv2.bitwise_and(HL_binary, S_binary)\n",
    "    mask_binary = cv2.bitwise_or(mask_binary, R_binary)    \n",
    "    return mask_binary\n",
    "\n",
    "def region_of_interest(img):\n",
    "    \"\"\"\n",
    "    Applies a regional mask on an image.\n",
    "    Only keeps the region of the image defined by the trapezoid formed from\n",
    "    `vertices` (see initialation block above). \n",
    "    \n",
    "    Retuns masked image with the rest of the image set to black.\n",
    "    \"\"\"\n",
    "    # Defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    # Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    # Filling pixels inside the trapezoid defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image \n",
    "############################## (END) #############################\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Lane Detection Functions\n",
    "These functions are used to determine (and display) the lane boundaries, curvature radius and vehicle offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "################### LANE DETECTION FUNCTIONS #####################\n",
    "def find_lane_pixels(binary_warped):\n",
    "    ''' This functions uses the window search method to find the lane pixels. '''\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # These will be the starting point for window to search for the left and right line\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Set number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 70\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 40\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        # Set boundaries of the window\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If found(pixels) > minpix(pixels), recenter next window at mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        \n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def search_around_poly(binary_warped, left, right):\n",
    "    ''' \n",
    "    This function will search around the previously detected lane lines for the next lane lines pixels.\n",
    "    Requires a previously detected lane line the binary image.\n",
    "    '''\n",
    "    # HYPERPARAMETER\n",
    "    # Set width of the margin around the previous polynomial to search\n",
    "    margin = 70\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Define polynomial to search arround\n",
    "    left_fit = left.current_fit\n",
    "    right_fit = right.current_fit\n",
    "    \n",
    "    # Set the area of search based on activated x-values within +/- margin of polynomial function\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(binary_warped, left, right):\n",
    "    '''\n",
    "    Detect lane line pixels and fit the best fit polynomial to lane line. \n",
    "    \n",
    "    This function uses sanity checks to verify that the lane line pixels return a\n",
    "    polinomial that is similar to the previously detected line \n",
    "    '''\n",
    "    # Find lane line pixels\n",
    "    if left.detected is True and right.detected is True:  # search around polynomial if previous lines detected\n",
    "        leftx, lefty, rightx, righty, out_img = search_around_poly(binary_warped, left, right)\n",
    "    else:  # use sliding window if previous line not detected\n",
    "        leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Generate 72 evenly spaced y-values that span the image height (less y_vals, faster processing)\n",
    "    y_vals = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0]//10)\n",
    "\n",
    "    # Fit a second order polynomial to each line using `np.polyfit`\n",
    "    try: \n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # If error deteccted, set new fit as best_fit, and set current_fit to None to skip sanity checks\n",
    "    except TypeError:\n",
    "        left_fit = left.best_fit\n",
    "        right_fit = right.best_fit\n",
    "        left.current_fit = None\n",
    "        right.current_fit = None\n",
    "    \n",
    "    try:\n",
    "        left_fitx = left_fit[0]*y_vals**2 + left_fit[1]*y_vals + left_fit[2]\n",
    "        right_fitx = right_fit[0]*y_vals**2 + right_fit[1]*y_vals + right_fit[2]\n",
    "\n",
    "        # Sanity checks for x-intercepts and x values \n",
    "        if ((len(left.current_fit) > 1) & (len(right.current_fit) > 1)):\n",
    "            # Find difference between the best \n",
    "            left.diffs = np.abs(left_fit - left.current_fit)\n",
    "            right.diffs = np.abs(right_fit - right.current_fit)\n",
    "            left_x_diff = np.abs(left_fitx[0] - left.bestx[0])\n",
    "            right_x_diff = np.abs(right_fitx[0] - right.bestx[0])\n",
    "\n",
    "            # Sanity checks\n",
    "            # Left line - check if similar to current line\n",
    "            if ((left.diffs[2] < 50) & (left_x_diff < 60)):\n",
    "                left.detected = True\n",
    "                left.current_fit = left_fit\n",
    "                left.bestx = weighted_average(left, left_fitx)\n",
    "            # New line is not similar to current, try window search for next frame \n",
    "            else:\n",
    "                left.detected = False\n",
    "                left.current_fit = []\n",
    "                left.bestx = weighted_average(left, left_fitx)\n",
    "                left.recent_xfitted.clear\n",
    "\n",
    "            # Right Line - check if similar to current line\n",
    "            if ((right.diffs[2] < 50) & (right_x_diff < 60)):\n",
    "                right.detected = True\n",
    "                right.current_fit = right_fit\n",
    "                right.bestx = weighted_average(right, right_fitx)\n",
    "            # New line is not similar to current, try window search for next frame \n",
    "            else:\n",
    "                right.detected = False\n",
    "                right.current_fit = []\n",
    "                right.bestx = weighted_average(right, right_fitx)\n",
    "                right.recent_xfitted.clear\n",
    "        \n",
    "        # If no current_fit, set it as the new fit (e.g. first frame, error)         \n",
    "        else:\n",
    "            left.detected = True\n",
    "            right.detected = True\n",
    "            left.current_fit = left_fit\n",
    "            right.current_fit = right_fit\n",
    "            # Set bestx as new x-fitted values if empty, otherwise clear queue \n",
    "            if left.bestx == None:\n",
    "                left.bestx = left_fitx\n",
    "            else:\n",
    "                left.recent_xfitted.clear\n",
    "                \n",
    "            if right.bestx == None:\n",
    "                right.bestx = right_fitx\n",
    "            else:\n",
    "                right.recent_xfitted.clear\n",
    "\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left.detected = False\n",
    "        right.detected = False\n",
    "        left.current_fit = None\n",
    "        right.current_fit = None\n",
    "        # If their bestx is empty, assign a polynomial and clear the queue of previously detected x-fitted values\n",
    "        if left.bestx is None:\n",
    "            left.bestx = 1*y_vals**2 + 1*y_vals\n",
    "            left.recent_xfitted.clear\n",
    "        if right.bestx is None:\n",
    "            right.bestx = 1*y_vals**2 + 1*y_vals\n",
    "            right.recent_xfitted.clear\n",
    "\n",
    "    # Calculate the best fit using the best x values  \n",
    "    left.best_fit = np.polyfit(y_vals, left.bestx, 2)\n",
    "    right.best_fit = np.polyfit(y_vals, right.bestx, 2)\n",
    "    \n",
    "    # Create image for output\n",
    "    zero_output = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    lines_image = np.zeros_like(zero_output)\n",
    "    draw_lane(lines_image, left.bestx, right.bestx, y_vals)\n",
    "    return lines_image, y_vals\n",
    "\n",
    "def weighted_average(h, fitx, n=7):\n",
    "    \"\"\" \n",
    "    Applies a weighted average to last 'n' x-fitted values to find the best fit\n",
    "    for lane line.\n",
    "    \n",
    "    h: handle of class object\n",
    "    \"\"\"\n",
    "    weights=[1,1,2,3,5,8,13]#,21,34,55]\n",
    "    run_len = len(h.recent_xfitted)  # get current length of queue\n",
    "\n",
    "    # Maintaining running window |f0,f1,f2,...,fn| of previous n x-values\n",
    "    if fitx is not None:\n",
    "        if run_len == n:  # queue is full\n",
    "            h.recent_xfitted.popleft()  # [f0<--,|f1,f2,...,fn|,fn+1]\n",
    "        else:             # queue not full\n",
    "            run_len += 1  # add 1 to length\n",
    "        h.recent_xfitted.append(fitx)  # [f0,|f1,f2,...,fn<--|,fn+1]\n",
    "    else:  # reduce queue if no x-fitted values are found\n",
    "        if len(h.recent_xfitted) > 0:\n",
    "            h.recent_xfitted.popleft()\n",
    "            run_len -= 1\n",
    "\n",
    "    # Compute weighted average\n",
    "    if len(h.recent_xfitted) > 0:\n",
    "        h.bestx = np.average(h.recent_xfitted, axis=0, weights=weights[:run_len])\n",
    "    return h.bestx\n",
    "\n",
    "def curvature_radius_real(y_vals, left, right):\n",
    "    ''' Calculates current radius of curvature in meters '''\n",
    "    # Assign metric value to pixels in each dimension\n",
    "    ym_per_pix = 30/720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/(right.best_fit[-1] - left.best_fit[-1]) # meters per pixel in x dimension\n",
    "    \n",
    "    y_eval = np.max(y_vals)\n",
    "    \n",
    "    # Convert best fit polynomial to real world values\n",
    "    left_fit_cr = np.polyfit(y_vals*ym_per_pix, left.bestx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(y_vals*ym_per_pix, right.bestx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate radius of curvature\n",
    "    left.radius_of_curvature = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right.radius_of_curvature = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "def vehicle_offset(img, left, right):\n",
    "    ''' Calculates difference between vehicle center and lane center '''\n",
    "    vehicle_center = img.shape[1] // 2  # center of vehicle is center of image\n",
    "    xm_per_pix = 3.7 / (right.bestx[-1] - left.bestx[-1])  # x-values of line nearest the vehicle\n",
    "    # Calculate x-value of lane center\n",
    "    left.line_base_pos = left.bestx[-1] - vehicle_center    # expects negative value\n",
    "    right.line_base_pos = right.bestx[-1] - vehicle_center  #expects positive value\n",
    "    vehicle_offset = left.line_base_pos + right.line_base_pos\n",
    "    return vehicle_offset*xm_per_pix\n",
    "\n",
    "def draw_lane(img, left_fitx, right_fitx, y_vals):\n",
    "    ''' Draws lane on input 'img' '''\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, y_vals]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, y_vals])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(img, np.int_([pts]), (0,255,0))\n",
    "\n",
    "def original_perspective(dest, warped_image, Minv):\n",
    "    ''' Unwarps the top-down view bck to the original perspective using Minv '''\n",
    "    img_size = (dest.shape[1], dest.shape[0])\n",
    "    original_img = cv2.warpPerspective(warped_image, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return original_img\n",
    "\n",
    "def weighted_img(init_img, img, α=1., β=0.3, γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is a blank image with the lane drawn on it from the original perspective.\n",
    "    \n",
    "    `init_img` is original unditorted image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "        initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(init_img, α, img, β, γ)\n",
    "\n",
    "def detected_lane(init_img, img, lane_offset, left, right):\n",
    "    ''' \n",
    "    This function will write the curvature radius and vehicle offset on input image.\n",
    "    The curvature radius is calculated by averaging the radius of each line.\n",
    "    '''\n",
    "    # Average of left and right curvature radii\n",
    "    radius_curvature = np.int32((left.radius_of_curvature + right.radius_of_curvature) / 2)\n",
    "    # Write curvature radius value\n",
    "    cv2.putText(init_img, \"Radius of Curvature: %s m\" % str(radius_curvature), (20, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    # Determine relative offset from lane center to vehicle center \n",
    "    if lane_offset < 0:  # left of center\n",
    "        offset_dir = str('{:.2f}'.format(np.abs(lane_offset)) + \"m left of center\")\n",
    "    elif lane_offset > 0:  # right of center\n",
    "        offset_dir = str('{:.2f}'.format(lane_offset) + \"m right of center\")\n",
    "    else:\n",
    "        offset_dir = \"center\"\n",
    "    # Write vehicle offset\n",
    "    cv2.putText(init_img, \"Vehicle is %s\" % offset_dir, (20, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    return weighted_img(init_img, img)\n",
    "\n",
    "############################## (END) #############################\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Lane Finding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#################### LANE DETECTION PIPELINE #####################\n",
    "# Define lane-finding pipeline function\n",
    "def process_image(img):\n",
    "    \"\"\"\n",
    "    This function serves as a pipeline to process each frame of the video file\n",
    "    using the functions defined above in a sequential method designed to undistort\n",
    "    the input image, find each lane line, determine the lane position, and calculate\n",
    "    curvature radius and vehicle offset.    \n",
    "    Returns a manipulated image of the input image with the lane region highlighted and info.\n",
    "    \"\"\"  \n",
    "    #### COPY OF IMAGE ####\n",
    "    image = np.copy(img)\n",
    "    \n",
    "    #### UNDISTORT IMAGE ####\n",
    "    undist = undistort(image)\n",
    "    \n",
    "    #### PERSPECTIVE TRANSFORM ####\n",
    "    image_T = elevate_perspective(undist)   \n",
    "    \n",
    "    #### COLOR SELECTION ####\n",
    "    hls_image_T = bgr2hls(image_T)\n",
    "    color_select = color_mask(image_T, hls_image_T)\n",
    "    \n",
    "    #### SOBEL & MAGNITUDE DIRECTION ####\n",
    "    gradx, dir_binary = sobel(image_T)\n",
    "    \n",
    "    #### COMBINE COLOR & SOBEL RESULTS ####\n",
    "    color_gradx = cv2.bitwise_or(color_select, gradx)\n",
    "    filtered_image = np.zeros_like(color_select)\n",
    "    filtered_image[(color_gradx == 1) & (dir_binary == 0)] = 1\n",
    "    \n",
    "    #### REGION OF INTEREST ####\n",
    "    masked_image = region_of_interest(filtered_image) # applies trapezoidal ROI\n",
    "        \n",
    "    #### FIND LANE PIXELS ####\n",
    "    output_image, y_vals = fit_polynomial(masked_image, Left, Right)\n",
    "        \n",
    "    #### CALCULATE REAL-WORLD RADIUS OF CURVATURE ####\n",
    "    curvature_radius_real(y_vals, Left, Right)\n",
    "\n",
    "    #### FIND OFFSET OF VEHICLE CENTER TO LANE CENTER #### \n",
    "    lane_offset = vehicle_offset(output_image, Left, Right)\n",
    "        \n",
    "    #### TRANSFORM IMAGE BACK TO ORIGINAL PERSPECTIVE #### \n",
    "    result_image = original_perspective(undist, output_image, Minv)\n",
    "\n",
    "    #### DISPLAY DETECTED LANE, CURVATURE RADIUS, VEHICLE OFFSET ON ORIGINAL UNDISTORTED IMAGE ####\n",
    "    lane_image = detected_lane(undist, result_image, lane_offset, Left, Right)\n",
    "\n",
    "    return lane_image #masked_img\n",
    "############################## (END) #############################\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Line() Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### CREATE 'Line()' CLASS ######################\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = deque() \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None    \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = np.array([])  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None\n",
    "        #y values for detected line pixels\n",
    "        self.ally = None  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Image Processing\n",
    "The code in this section will process all images in the 'test_images' folder and display the result. Press 'Q' to close each image window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fimage in test_images:\n",
    "    Left = Line()\n",
    "    Right = Line()\n",
    "    image = cv2.imread(fimage)\n",
    "    result = process_image(image)\n",
    "    \n",
    "    cv2.imshow('Result', result)\n",
    "    r = cv2.waitKey(0) & 0xFF\n",
    "    if r == ord('q'):\n",
    "        cv2.destroyWindow('Result')\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Video Processing\n",
    "The code in this section will process each frame of the 'project_video.mp4' and save the result video to 'project_video_output.mp4'.\n",
    "\n",
    "### project_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [04:30<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "##################### PROCESS VIDEO ######################\n",
    "Left = Line()   # create instance of Line() class for left lane line\n",
    "Right = Line()  # create instance of Line() class for right lane line\n",
    "video = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "# Loop through and process each frame of video file\n",
    "processed_video = video.fl_image(process_image)\n",
    "\n",
    "%time processed_video.write_videofile(\"project_video_output.mp4\", audio=False)\n",
    "\n",
    "video.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls> \n",
       "  <source src=\"project_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display output video post-processing\n",
    "project_video_output = \"project_video_output.mp4\"\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls> \n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
